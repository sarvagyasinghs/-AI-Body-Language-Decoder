{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522ef102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04b750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e74f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Make Detections\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Recolor image back to BGR for rendering\u001b[39;00m\n\u001b[1;32m     33\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/av/lib/python3.11/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(input_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image})\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/av/lib/python3.11/site-packages/mediapipe/python/solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Create a VideoCapture object for the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was read successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame.\")\n",
    "            break\n",
    "\n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                                  )\n",
    "\n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40766faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "num_coords = len(results.pose_landmarks.landmark) + len(results.face_landmarks.landmark)\n",
    "num_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f512b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa75e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e27b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b3444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94d6c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sarvagyasamridhsingh/Documents/Programming/bodylang/coordsfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8868ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>y248</th>\n",
       "      <th>z248</th>\n",
       "      <th>v248</th>\n",
       "      <th>x249</th>\n",
       "      <th>y249</th>\n",
       "      <th>z249</th>\n",
       "      <th>v249</th>\n",
       "      <th>x250</th>\n",
       "      <th>y250</th>\n",
       "      <th>z250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.544152</td>\n",
       "      <td>0.418648</td>\n",
       "      <td>-0.748952</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>0.560252</td>\n",
       "      <td>0.359410</td>\n",
       "      <td>-0.697521</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0.574597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506981</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449573</td>\n",
       "      <td>0.494465</td>\n",
       "      <td>0.037965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484140</td>\n",
       "      <td>0.470787</td>\n",
       "      <td>-0.005179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.543450</td>\n",
       "      <td>0.420560</td>\n",
       "      <td>-0.940694</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.560227</td>\n",
       "      <td>0.359526</td>\n",
       "      <td>-0.884563</td>\n",
       "      <td>0.999468</td>\n",
       "      <td>0.574592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509077</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449189</td>\n",
       "      <td>0.498841</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483930</td>\n",
       "      <td>0.472063</td>\n",
       "      <td>-0.004669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.542778</td>\n",
       "      <td>0.421553</td>\n",
       "      <td>-1.008881</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.560195</td>\n",
       "      <td>0.359586</td>\n",
       "      <td>-0.951786</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.574592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507708</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.496821</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484267</td>\n",
       "      <td>0.471379</td>\n",
       "      <td>-0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.542510</td>\n",
       "      <td>0.422576</td>\n",
       "      <td>-1.059535</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.560203</td>\n",
       "      <td>0.359707</td>\n",
       "      <td>-1.002627</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>0.574623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508036</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450814</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>0.040259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484653</td>\n",
       "      <td>0.472289</td>\n",
       "      <td>-0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.542055</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>-1.004646</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.560144</td>\n",
       "      <td>0.359816</td>\n",
       "      <td>-0.948520</td>\n",
       "      <td>0.999148</td>\n",
       "      <td>0.574594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508058</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451343</td>\n",
       "      <td>0.496528</td>\n",
       "      <td>0.041381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484699</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>-0.003742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class        x1        y1        z1        v1        x2        y2  \\\n",
       "0  Happy  0.544152  0.418648 -0.748952  0.999782  0.560252  0.359410   \n",
       "1  Happy  0.543450  0.420560 -0.940694  0.999741  0.560227  0.359526   \n",
       "2  Happy  0.542778  0.421553 -1.008881  0.999687  0.560195  0.359586   \n",
       "3  Happy  0.542510  0.422576 -1.059535  0.999634  0.560203  0.359707   \n",
       "4  Happy  0.542055  0.423368 -1.004646  0.999610  0.560144  0.359816   \n",
       "\n",
       "         z2        v2        x3  ...      y248      z248  v248      x249  \\\n",
       "0 -0.697521  0.999569  0.574597  ...  0.506981  0.005223   0.0  0.449573   \n",
       "1 -0.884563  0.999468  0.574592  ...  0.509077  0.006211   0.0  0.449189   \n",
       "2 -0.951786  0.999341  0.574592  ...  0.507708  0.006483   0.0  0.449310   \n",
       "3 -1.002627  0.999219  0.574623  ...  0.508036  0.007032   0.0  0.450814   \n",
       "4 -0.948520  0.999148  0.574594  ...  0.508058  0.008001   0.0  0.451343   \n",
       "\n",
       "       y249      z249  v249      x250      y250      z250  \n",
       "0  0.494465  0.037965   0.0  0.484140  0.470787 -0.005179  \n",
       "1  0.498841  0.038961   0.0  0.483930  0.472063 -0.004669  \n",
       "2  0.496821  0.038873   0.0  0.484267  0.471379 -0.004646  \n",
       "3  0.496108  0.040259   0.0  0.484653  0.472289 -0.004454  \n",
       "4  0.496528  0.041381   0.0  0.484699  0.472200 -0.003742  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7e77f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a7c9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4bf24d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240            Namaste\n",
       "541              Angry\n",
       "214            Namaste\n",
       "492              Angry\n",
       "190            Namaste\n",
       "            ...       \n",
       "309         Victorious\n",
       "387               Kiss\n",
       "370         Victorious\n",
       "173            Namaste\n",
       "589    Wakanda forever\n",
       "Name: class, Length: 201, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa5eefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acb28680",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00686ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train.values, y_train.values)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0b201bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04201b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Namaste', 'Angry', 'Namaste', 'Angry', 'Namaste', 'Happy',\n",
       "       'Happy', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Wakanda forever', 'Sad', 'Angry', 'Wakanda forever',\n",
       "       'Wakanda forever', 'Namaste', 'Kiss', 'Namaste', 'Wakanda forever',\n",
       "       'Namaste', 'Angry', 'Namaste', 'Victorious', 'Namaste',\n",
       "       'Victorious', 'Angry', 'Kiss', 'Sad', 'Kiss', 'Wakanda forever',\n",
       "       'Namaste', 'Kiss', 'Angry', 'Sad', 'Namaste', 'Angry', 'Angry',\n",
       "       'Happy', 'Angry', 'Victorious', 'Kiss', 'Happy', 'Victorious',\n",
       "       'Happy', 'Angry', 'Happy', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Wakanda forever', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Victorious', 'Wakanda forever', 'Happy', 'Namaste', 'Namaste',\n",
       "       'Angry', 'Namaste', 'Sad', 'Victorious', 'Victorious', 'Namaste',\n",
       "       'Wakanda forever', 'Sad', 'Happy', 'Angry', 'Victorious',\n",
       "       'Wakanda forever', 'Victorious', 'Angry', 'Namaste', 'Happy',\n",
       "       'Wakanda forever', 'Sad', 'Namaste', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Wakanda forever', 'Kiss', 'Wakanda forever', 'Kiss',\n",
       "       'Angry', 'Victorious', 'Victorious', 'Angry', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Sad', 'Kiss', 'Kiss',\n",
       "       'Wakanda forever', 'Angry', 'Victorious', 'Victorious', 'Namaste',\n",
       "       'Angry', 'Sad', 'Wakanda forever', 'Sad', 'Namaste', 'Victorious',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Angry', 'Namaste', 'Namaste', 'Sad', 'Namaste', 'Wakanda forever',\n",
       "       'Wakanda forever', 'Namaste', 'Happy', 'Sad', 'Namaste', 'Angry',\n",
       "       'Kiss', 'Namaste', 'Sad', 'Victorious', 'Namaste', 'Sad',\n",
       "       'Wakanda forever', 'Wakanda forever', 'Kiss', 'Wakanda forever',\n",
       "       'Happy', 'Angry', 'Happy', 'Kiss', 'Angry', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Angry', 'Namaste', 'Kiss', 'Sad', 'Happy', 'Sad',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Sad', 'Sad', 'Kiss',\n",
       "       'Namaste', 'Wakanda forever', 'Happy', 'Namaste',\n",
       "       'Wakanda forever', 'Namaste', 'Victorious', 'Namaste', 'Angry',\n",
       "       'Happy', 'Wakanda forever', 'Happy', 'Sad', 'Sad', 'Victorious',\n",
       "       'Angry', 'Happy', 'Kiss', 'Angry', 'Kiss', 'Happy', 'Sad', 'Sad',\n",
       "       'Angry', 'Happy', 'Happy', 'Sad', 'Kiss', 'Victorious', 'Happy',\n",
       "       'Namaste', 'Namaste', 'Namaste', 'Angry', 'Kiss',\n",
       "       'Wakanda forever', 'Happy', 'Sad', 'Wakanda forever', 'Angry',\n",
       "       'Sad', 'Victorious', 'Kiss', 'Victorious', 'Namaste',\n",
       "       'Wakanda forever'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c723475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ed4194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9850746268656716\n",
      "rc 0.9950248756218906\n",
      "rf 0.9751243781094527\n",
      "gb 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test.values)\n",
    "    print(algo, accuracy_score(y_test.values, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b293f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Namaste', 'Angry', 'Namaste', 'Angry', 'Namaste', 'Happy',\n",
       "       'Happy', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Wakanda forever', 'Sad', 'Angry', 'Wakanda forever',\n",
       "       'Wakanda forever', 'Namaste', 'Kiss', 'Namaste', 'Wakanda forever',\n",
       "       'Namaste', 'Angry', 'Namaste', 'Victorious', 'Namaste',\n",
       "       'Victorious', 'Angry', 'Kiss', 'Sad', 'Kiss', 'Wakanda forever',\n",
       "       'Namaste', 'Kiss', 'Angry', 'Sad', 'Namaste', 'Angry', 'Angry',\n",
       "       'Happy', 'Angry', 'Victorious', 'Kiss', 'Happy', 'Victorious',\n",
       "       'Happy', 'Angry', 'Happy', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Wakanda forever', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Victorious', 'Wakanda forever', 'Happy', 'Namaste', 'Namaste',\n",
       "       'Angry', 'Namaste', 'Sad', 'Victorious', 'Victorious', 'Namaste',\n",
       "       'Wakanda forever', 'Sad', 'Happy', 'Angry', 'Victorious',\n",
       "       'Wakanda forever', 'Victorious', 'Angry', 'Namaste', 'Happy',\n",
       "       'Wakanda forever', 'Sad', 'Namaste', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Wakanda forever', 'Kiss', 'Wakanda forever', 'Kiss',\n",
       "       'Angry', 'Victorious', 'Victorious', 'Angry', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Sad', 'Kiss', 'Kiss',\n",
       "       'Wakanda forever', 'Angry', 'Victorious', 'Victorious', 'Namaste',\n",
       "       'Angry', 'Sad', 'Wakanda forever', 'Sad', 'Namaste', 'Victorious',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Angry', 'Namaste', 'Namaste', 'Sad', 'Namaste', 'Wakanda forever',\n",
       "       'Wakanda forever', 'Namaste', 'Happy', 'Sad', 'Namaste', 'Angry',\n",
       "       'Kiss', 'Namaste', 'Sad', 'Victorious', 'Namaste', 'Sad',\n",
       "       'Wakanda forever', 'Wakanda forever', 'Kiss', 'Wakanda forever',\n",
       "       'Happy', 'Angry', 'Happy', 'Kiss', 'Angry', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Angry', 'Namaste', 'Kiss', 'Sad', 'Happy', 'Sad',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Sad', 'Sad', 'Kiss',\n",
       "       'Namaste', 'Wakanda forever', 'Happy', 'Namaste',\n",
       "       'Wakanda forever', 'Namaste', 'Victorious', 'Namaste', 'Angry',\n",
       "       'Happy', 'Wakanda forever', 'Happy', 'Sad', 'Sad', 'Victorious',\n",
       "       'Angry', 'Happy', 'Kiss', 'Angry', 'Kiss', 'Happy', 'Sad', 'Sad',\n",
       "       'Angry', 'Happy', 'Happy', 'Sad', 'Kiss', 'Victorious', 'Happy',\n",
       "       'Namaste', 'Namaste', 'Namaste', 'Angry', 'Kiss',\n",
       "       'Wakanda forever', 'Happy', 'Sad', 'Wakanda forever', 'Angry',\n",
       "       'Sad', 'Victorious', 'Kiss', 'Victorious', 'Namaste',\n",
       "       'Wakanda forever'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ee3cbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Namaste', 'Angry', 'Namaste', 'Angry', 'Namaste', 'Happy',\n",
       "       'Happy', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Wakanda forever', 'Sad', 'Angry', 'Wakanda forever',\n",
       "       'Wakanda forever', 'Namaste', 'Kiss', 'Namaste', 'Wakanda forever',\n",
       "       'Namaste', 'Angry', 'Namaste', 'Victorious', 'Namaste',\n",
       "       'Victorious', 'Angry', 'Kiss', 'Sad', 'Kiss', 'Wakanda forever',\n",
       "       'Namaste', 'Kiss', 'Angry', 'Sad', 'Namaste', 'Angry', 'Angry',\n",
       "       'Happy', 'Angry', 'Victorious', 'Kiss', 'Happy', 'Victorious',\n",
       "       'Happy', 'Angry', 'Happy', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Wakanda forever', 'Victorious', 'Wakanda forever', 'Kiss',\n",
       "       'Victorious', 'Wakanda forever', 'Happy', 'Namaste', 'Namaste',\n",
       "       'Angry', 'Victorious', 'Sad', 'Victorious', 'Victorious',\n",
       "       'Namaste', 'Wakanda forever', 'Sad', 'Happy', 'Angry',\n",
       "       'Victorious', 'Wakanda forever', 'Victorious', 'Angry', 'Namaste',\n",
       "       'Happy', 'Wakanda forever', 'Sad', 'Namaste', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Victorious', 'Kiss', 'Wakanda forever', 'Kiss',\n",
       "       'Angry', 'Victorious', 'Victorious', 'Angry', 'Namaste', 'Namaste',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Sad', 'Kiss', 'Kiss',\n",
       "       'Wakanda forever', 'Angry', 'Victorious', 'Victorious', 'Namaste',\n",
       "       'Angry', 'Sad', 'Wakanda forever', 'Sad', 'Namaste', 'Victorious',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Wakanda forever', 'Namaste',\n",
       "       'Angry', 'Namaste', 'Namaste', 'Sad', 'Namaste', 'Victorious',\n",
       "       'Wakanda forever', 'Victorious', 'Happy', 'Sad', 'Namaste',\n",
       "       'Angry', 'Kiss', 'Namaste', 'Sad', 'Victorious', 'Namaste', 'Sad',\n",
       "       'Wakanda forever', 'Wakanda forever', 'Kiss', 'Wakanda forever',\n",
       "       'Happy', 'Angry', 'Happy', 'Kiss', 'Angry', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Angry', 'Namaste', 'Kiss', 'Sad', 'Happy', 'Sad',\n",
       "       'Namaste', 'Kiss', 'Wakanda forever', 'Sad', 'Sad', 'Kiss',\n",
       "       'Namaste', 'Wakanda forever', 'Happy', 'Namaste',\n",
       "       'Wakanda forever', 'Namaste', 'Victorious', 'Namaste', 'Angry',\n",
       "       'Happy', 'Wakanda forever', 'Happy', 'Sad', 'Sad', 'Victorious',\n",
       "       'Angry', 'Happy', 'Kiss', 'Angry', 'Kiss', 'Happy', 'Sad', 'Sad',\n",
       "       'Angry', 'Happy', 'Happy', 'Sad', 'Kiss', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Namaste', 'Namaste', 'Angry', 'Kiss',\n",
       "       'Wakanda forever', 'Happy', 'Sad', 'Wakanda forever', 'Angry',\n",
       "       'Sad', 'Victorious', 'Kiss', 'Victorious', 'Namaste',\n",
       "       'Wakanda forever'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74533f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "208a562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1556e940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31708c8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m        \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Make Detections\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(image)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(results.face_landmarks)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Recolor image back to BGR for rendering\u001b[39;00m\n\u001b[1;32m     19\u001b[0m image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m   \n",
      "File \u001b[0;32m~/anaconda3/envs/av/lib/python3.11/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(input_data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image})\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/av/lib/python3.11/site-packages/mediapipe/python/solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mwait_until_idle()\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Extract Face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#               Export to CSV\n",
    "#             with open('coords.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "\n",
    "            # Make Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Grab ear coords\n",
    "            coords = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "            cv2.rectangle(image, \n",
    "                          (coords[0], coords[1]+5), \n",
    "                          (coords[0]+len(body_language_class)*20, coords[1]-30), \n",
    "                          (245, 117, 16), -1)\n",
    "            cv2.putText(image, body_language_class, coords, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "            \n",
    "            # Display Class\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display Probability\n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(body_language_prob[np.argmax(body_language_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = tuple(np.multiply(\n",
    "    np.array(\n",
    "        (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x, \n",
    "         results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "    , [640, 480]).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1235ae0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5861707925796509"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6be0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (4.8.0.76)\n",
      "Requirement already satisfied: mediapipe in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (0.10.3)\n",
      "Requirement already satisfied: numpy in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: absl-py in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (4.8.0.76)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sarvagyasamridhsingh/anaconda3/envs/av/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python mediapipe numpy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
